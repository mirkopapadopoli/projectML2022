```{r}
#import library
library(e1071)
install.packages(e1071)
library(ggplot2)
install.packages(ggplot2)
library(dplyr)
install.packages(dplyr)
library(Hmisc)
install.packages(Hmisc)
library(corrplot)
install.packages(corrplot)
library(caret)
install.packages(caret)
library(plyr)
install.packages(plyr)
library(rpart)
install.packages(rpart)
library(rattle)
install.packages(rattle)
library(ROCR)
install.packages(ROCR)
library(FactoMineR)
install.packages(FactoMineR)
library(factoextra)
install.packages(factoextra)
library(C50)
install.packages(C50)
library(pROC)
install.packages(pROC)
```

```{r}
#import csv
waterquality = read.csv("waterQuality.csv")
```

```{r}
#preprocessing se duplicati e nulli
sum(duplicated(waterquality))
sum(is.na(waterquality))
```

```{r}
 
waterquality_pre <- waterquality[!(waterquality$is_safe =="#NUM!"),]
```

```{r}
#conversione variabili
waterquality_pre$ammonia = as.numeric(waterquality_pre$ammonia)
waterquality_pre$is_safe = factor(waterquality_pre$is_safe)
```

```{r}
head(waterquality_pre)
```

```{r}
sapply(waterquality_pre, class)
```

```{r}
describe(waterquality_pre)
```

```{r}
dim(waterquality_pre)
```

```{r}
ggplot(data.frame(waterquality_pre$is_safe), aes(x=waterquality_pre$is_safe)) +
  geom_bar()
```

```{r}
par(mfrow = c(1, 4))

for(i in names(waterquality_pre)[1:20]){
  hist(waterquality_pre[[i]], main = paste("Hist of", i)) 
}

```

```{r}
col_names <- names(waterquality_pre)[1:20]
par(mfrow = c(1, 5))

for(i in col_names) {
  boxplot(scale(waterquality_pre[[i]]), col = "orange", main = paste("Boxplot of", i))
}

```

```{r}
col_names <- names(waterquality_pre)[1:20]
par(mfrow = c(1, 5))

for(i in col_names) {
  ggplot(waterquality_pre, aes(x = colnames(waterquality_pre)[i], fill = is_safe, color = is_safe)) + 
    geom_density(alpha = 0.5) + 
    ggtitle(paste("Density of", i))
}
```

```{r}
ggplot(waterquality_pre, aes(x = waterquality_pre$ammonia, fill = is_safe, color = is_safe)) + 
    geom_density(alpha = 0.5) + 
    ggtitle(paste("Density of", names(waterquality_pre)[1])
    )
```

```{r}
describe(waterquality)
```

```{r}
#corr matrix
card.cor = cor(waterquality[,1:3])
corrplot(card.cor)
```

```{r}
#relazione se è frode usando torta
sub.fraud = waterquality[which(waterquality$fraud == 1),]
sub.nrow = nrow(sub.fraud)
for(i in 4:7){
  sub.zero = length(sub.fraud[which(sub.fraud[,i] == 0), i])
  sub.one = sub.nrow - sub.zero
  slices <- c(sub.zero, sub.one)
  lbls <- c("non c'e'", "c'e'")
  pct <- round(slices/sum(slices)*100)
  lbls <- paste(lbls, pct) # add percents to labels
  lbls <- paste(lbls,"%",sep="") # ad % to labels
  pie(slices,labels = lbls, col=rainbow(length(lbls)),
   main=colnames(waterquality)[i])
}
#se c'è stata una frode, sicuramente è perché non c'era il pin
```

```{r}
sub.nofraud = waterquality[which(waterquality$fraud == 0),]
sub.nonrow = nrow(sub.nofraud)
for(i in 4:7){
  sub.zero = length(sub.nofraud[which(sub.nofraud[,i] == 0), i])
  sub.one = sub.nonrow - sub.zero
  slices <- c(sub.zero, sub.one)
  lbls <- c("non c'e'", "c'e'")
  pct <- round(slices/sum(slices)*100)
  lbls <- paste(lbls, pct) # add percents to labels
  lbls <- paste(lbls,"%",sep="") # ad % to labels
  pie(slices,labels = lbls, col=rainbow(length(lbls)),
   main=colnames(waterquality)[i])
}
```

PARTE PCA

```{r}
res.pca <- PCA(waterquality_pre[,!names(waterquality_pre) %in% c("is_safe")], graph = FALSE)
eig.val <- get_eigenvalue(res.pca)
eig.val
```

```{r}
res.pca <- PCA(waterquality_pre[,!names(waterquality_pre) %in% c("is_safe")], graph = FALSE, ncp = 10, scale = TRUE)
```

```{r}
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
var <- get_pca_var(res.pca)
```

```{r}
fviz_pca_var(res.pca, col.var = "black")
```

```{r}
ind <- get_pca_ind(res.pca)

```

```{r}
fviz_pca_ind(res.pca, col.ind = 'cos2', gradient.cols = c('#00AFBB', '#E7B800', '#FC4E07'),
repel = TRUE # Avoid text overlapping (slow if many points)
)
```

```{r}
split.data = function(data, p = 0.7, s = 1){
set.seed(s)
index = sample(1:dim(data)[1])
train = data[index[1:floor(dim(data)[1] * p)], ]
test = data[index[((ceiling(dim(data)[1] * p)) + 1):dim(data)[1]], ]
return(list(train=train, test=test)) } 
```

```{r}
dataframe_pca=as.data.frame(ind$coord)
dataframe_pca$is_safe = waterquality_pre$is_safe
```

PARTE DECISION TREE

```{r}
allset= split.data(dataframe_pca, s = 333)
trainset= allset$train
testset= allset$test
prop.table(table(trainset$is_safe))
```

```{r}
train_models = function(dataframe, grid, tipo, s = 44){

  set.seed(s)
  # Define the number of folds
  k = 10
  
  # Split the data into k folds
  folds = createFolds(dataframe$is_safe, k = k)
  str(folds)
  # Define an empty list to store the models
  models = list()
  
  # Loop through the grid of parameter values
  for (i in 1:nrow(grid)) {
      # Define an empty vector to store the accuracy
      accuracy = numeric()
      # Loop through the k-folds
      for (j in 1:k) {
          # Get the training and testing sets
          train_ind = folds[[j]]
          test_ind = -train_ind
          
          train_data = dataframe[train_ind, ]
          test_data = dataframe[test_ind, ]
        
          # Fit the model
          if(tipo == "rpart")
          {
            model = rpart(is_safe ~ ., 
                             data = train_data, 
                             method = "class",
                             control = rpart.control(
                               minsplit = grid[i, "minsplit"],
                               maxdepth = grid[i, "maxdepth"]))
          }
          else{
            model = svm(is_safe ~ ., 
                        data=train_data,
                        kernel = grid[i, "kernel"],
                        cost = grid[i, "C"],
                        scale=TRUE)
          }
        
          # Make predictions on the test data
          predictions = predict(model, test_data, type = "class")
          
          confusion.matrix.model = table(test_data$is_safe, predictions)
          accuracy[j] = sum(diag(confusion.matrix.model))/sum(confusion.matrix.model)
      }
    
      # Store the model and its mean accuracy in the list
      models[[i]] = list(model = model, mean_accuracy = mean(accuracy))
  }
  
  # Find the model with the highest mean accuracy
  best_model = models[[which.max(sapply(models, function(x) x$mean_accuracy))]]
  
  # View the best model
  return(best_model$model)
}
```

```{r}
grid_tree = expand.grid(minsplit = c(2, 4), maxdepth = c(3, 5, 7, 9))
model.tree = train_models(trainset, grid_tree, "rpart", 47)
```

```{r}
model.tree
```

```{r}
fancyRpartPlot(model.tree)
```

```{r}
test.tree = testset[,!names(testset) %in% c("is_safe")]
testset$Prediction <- predict(model.tree, test.tree, type = "class")
```

```{r}
confusionmatrix.tree = table(testset$is_safe, testset$Prediction)
sum(diag(confusionmatrix.tree))/sum(confusionmatrix.tree)

```

```{r}
printcp(model.tree)
```

```{r}
plotcp(model.tree)
```

```{r}
model.treePR = prune(model.tree, cp=.05)
```

```{r}
fancyRpartPlot(model.treePR)
```

```{r}
testset$PredictionPR <- predict(model.treePR, test.tree, type = "class")
result.treePR = confusionMatrix(testset$PredictionPR, testset[,c("is_safe")], mode = "prec_recall")
result.treePR
```

PARTE SVM

```{r}
grid_svm = expand.grid(C = c(1), kernel = c("radial"))
svm.model = train_models(trainset, grid_svm, "svm", 42)
#svm.model = svm(is_safe ~ ., data=trainset, kernel='radial', cost=1, scale=TRUE) 
```

```{r}
print(svm.model)
```

```{r}
test.svm = testset[,!names(testset) %in% c("is_safe","Prediction","PredictionPR")]
```

```{r}
svm.pred = predict(svm.model, test.svm)

```

```{r}
result.svm = confusionMatrix(svm.pred, testset$is_safe, mode = "prec_recall")
result.svm
```

```{r}
#tuned = tune.svm(is_safe ~ ., data = trainset,kernel='radial',
#cost=c(10,0.1,1,0.01))
grid_svmT = expand.grid(C = c(1, 10, 100), kernel = c("radial", "polynomial", "linear"))
svmT.model = train_models(trainset, grid_svmT, "svm", 42)
#svmT = tuned$best.model
```

```{r}
svmT.pred = predict(svmT.model, test.svm)
```

```{r}
print(svmT.model)
```

```{r}
result.svmT = confusionMatrix(svmT.pred, testset$is_safe, mode = "prec_recall")
result.svmT
```

PARTE ROC E AUC

```{r}
generate_roc_single_model = function(model, test, targetoption, typemodel){
  pred.model.prob = predict(model, test[,!names(test) %in% c("is_safe")], type = "prob")
  print(pred.model.prob)
  pred.model.prob.targoption = pred.model.prob[, targetoption]
  
  pred.rocr.model = prediction(pred.model.prob.targoption, test$is_safe)
  perf.rocr.model = performance(pred.rocr.model, measure = "auc", x.measure = "cutoff")
  
  perf.targoption.rocr.model = performance(pred.rocr.model, "tpr", "fpr")
  plot(perf.targoption.rocr.model, colorize = T, main=paste("AUC:",(perf.rocr.model@y.values)))
  abline(a=0, b=1)
}
```

```{r}
generate_roc_single_model(model.treePR, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 2, "rpart")
```

```{r}
generate_roc_single_model(model.treePR, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 1, "rpart")
```

```{r}
pred.treePR.prob = predict(model.treePR, test.tree, type = "prob")
pred.treePR.prob.safe = pred.treePR.prob[, 2] 
pred.treePR.prob.not_safe = pred.treePR.prob[, 1]
```

```{r}
#pred.rocr.treePR = prediction(pred.treePR.roc, testset$is_safe) 
pred.rocr.treePR = prediction(pred.treePR.prob.safe, testset$is_safe) 
perf.rocr.treePR = performance(pred.rocr.treePR, measure = "auc", x.measure = "cutoff")
perf.tpr.rocr.treePR = performance(pred.rocr.treePR, "tpr","fpr")
```

```{r}
plot(perf.tpr.rocr.treePR, colorize=T,main=paste("AUC:",(perf.rocr.treePR@y.values))) 
abline(a=0, b=1)
```

```{r}
generate_roc_single_model(svmT.model, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 2, "rpart")
```

```{r}
pred.model.prob = predict(svmT.model, testset[,!names(testset) %in% c("is_safe","Prediction","PredictionPR")], probability = T)
```

```{r}
tuned2 = tune.svm(is_safe ~ ., data = trainset,kernel='radial',
cost=c(10,0.1,1,0.01), prob = TRUE)
pred.svmT.prob = predict(tuned2$best.model, test.tree, probability=TRUE)
prob.svmT = attr(pred.svmT.prob, "probabilities")
pred.svmT.roc = prob.svmT[, 2] 
```

```{r}
pred.rocr.svmT = prediction(pred.svmT.roc, testset$is_safe  ) 
perf.rocr.svmT = performance(pred.rocr.svmT, measure = 'auc', x.measure = 'cutoff')
perf.tpr.rocr.svmT = performance(pred.rocr.svmT, "tpr","fpr") 

```

```{r}
plot(perf.tpr.rocr.svmT, colorize=T,main=paste("AUC:",(perf.rocr.svmT@y.values)))
abline(a=0, b=1)
```

```{r}
opt.cut = function(perf, pred){
 cut.ind = mapply(FUN=function(x, y, p){
 d = (x - 0)^2 + (y-1)^2
 ind = which(d == min(d))
 c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
 cutoff = p[[ind]])
 }, perf@x.values, perf@y.values, pred@cutoffs)
}
```

```{r}
print(opt.cut(perf.tpr.rocr.svmT, pred.rocr.svmT))
```

```{r}
control = trainControl(method = "repeatedcv", number = 10,repeats = 3,
classProbs = TRUE, summaryFunction = twoClassSummary)
```

```{r}
comp_models_roc = function(trainset, meth, control, testset, color, added){
  model= train(make.names(is_safe) ~ ., data = trainset, method = meth, metric =
"ROC", trControl = control)
  probs = predict(model, testset[,! names(testset) %in% c("is_safe")], type = "prob")
  colnames(probs)[1] ="no"
  colnames(probs)[2] ="yes"
  ROC = roc(response = testset[,c("is_safe")], predictor = probs$yes,
  levels = levels(testset[,c("is_safe")]), direction = ">")
  return(ROC)
}
```

```{r}
control = trainControl(method = "repeatedcv", number = 10,repeats = 3,
classProbs = TRUE, summaryFunction = twoClassSummary)

set.seed(33)

comp_tree = comp_models_roc(trainset, "rpart", control,  testset[,! names(testset) %in% c("Prediction", "PredictionPR")], "green", TRUE)
plot(comp_tree,type="S", col="blue")

#comp_svm = comp_models_roc(trainset, "svmRadial", control,  testset[,! names(testset) %in% c("Prediction", "PredictionPR")], "blue", FALSE)
#plot(comp_svm,add = TRUE, col="green")
```

```{r}
comp_svm[2]
comp_tree[2]
```

```{r}
cv.values = resamples(list(svm=svm.model, rpart = rpart.model))
summary(cv.values)
```

```{r}
dotplot(cv.values, metric = "ROC") 

```

```{r}
bwplot(cv.values, layout = c(3, 1)) 

```

```{r}
splom(cv.values,metric="ROC")
```
