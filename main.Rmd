```{r}
#import library
install.packages(e1071)
library(e1071)
install.packages(ggplot2)
library(ggplot2)
install.packages(dplyr)
library(dplyr)
install.packages(Hmisc)
library(Hmisc)
install.packages(corrplot)
library(corrplot)
install.packages(caret)
library(caret)
install.packages(plyr)
library(plyr)
install.packages(rpart)
library(rpart)
install.packages(rattle)
library(rattle)
install.packages(ROCR)
library(ROCR)
install.packages(FactoMineR)
library(FactoMineR)
install.packages(factoextra)
library(factoextra)
install.packages(C50)
library(C50)
install.packages(pROC)
library(pROC)
```

```{r}
#importo il dataset dal file csv
waterquality = read.csv("waterQuality.csv")
```

```{r}
 #controllo se i dati sono duplicati e nulli
sum(duplicated(waterquality))
sum(is.na(waterquality))
```

```{r}
 #rimozioni di righe con il valore #NUM!
waterquality_pre <- waterquality[!(waterquality$is_safe =="#NUM!"),]
```

```{r}
#conversione variabili
waterquality_pre$ammonia = as.numeric(waterquality_pre$ammonia)
waterquality_pre$is_safe = factor(waterquality_pre$is_safe)
```

```{r}
#mostro le prime 6 righe del dataset
head(waterquality_pre)
```

```{r}
#mostro le classi delle colonne del dataset
sapply(waterquality_pre, class)
```

```{r}
#ottengo un analisi dei ogni singola colonna 
describe(waterquality_pre)
```

```{r}
#vedo la dimensione del dataset
dim(waterquality_pre)
```

```{r}
#plotto il numero di istanze con target = 1 e = 0
ggplot(data.frame(waterquality_pre$is_safe), aes(x=waterquality_pre$is_safe)) +
  geom_bar()
```

```{r}
#divido in 4 rettangoli l'area di visualizzazione
par(mfrow = c(1, 4))

#mostro tutti gli istogrammi per ogni feature, mettendone una per rettangolo
for(i in names(waterquality_pre)[1:20]){
  hist(waterquality_pre[[i]], main = paste("Hist of", i)) 
}

```

```{r}
#ottengo i nomi del dataset, tranne della target
col_names <- names(waterquality_pre)[1:20]
#divido in 5 rettangoli la zona di visualizzazione
par(mfrow = c(1, 5))

#mostro i boxplot per ogni feature
for(i in col_names) {
  boxplot(scale(waterquality_pre[[i]]), col = "orange", main = paste("Boxplot of", i))
}

```

```{r}
col_names <- names(waterquality_pre)[1:20]
par(mfrow = c(1, 5))

for(i in col_names) {
  ggplot(waterquality_pre, aes(x = colnames(waterquality_pre)[i], fill = is_safe, color = is_safe)) + 
    geom_density(alpha = 0.5) + 
    ggtitle(paste("Density of", i))
}
```

```{r}
ggplot(waterquality_pre, aes(x = waterquality_pre$ammonia, fill = is_safe, color = is_safe)) + 
    geom_density(alpha = 0.5) + 
    ggtitle(paste("Density of", names(waterquality_pre)[1])
    )
```

```{r}
f_ggplot <- function(v_column){
    ggplot(data = waterquality_pre, 
           aes(group = waterquality_pre$is_safe, 
               fill = is_safe)) +
    geom_density(aes_string(x = v_column),
                 alpha = 0.4) +
    labs(title = paste("Title for variable", v_column))
}
```

```{r}
coll = colnames(waterquality_pre[,!names(waterquality_pre) %in% c("is_safe")])
lapply(coll, f_ggplot)
```

```{r}
#corr matrix
card.cor = cor(waterquality_pre[,1:20])
diag(card.cor) = 0
corrplot(card.cor, type = "lower")
```

PARTE PCA

```{r}
res.pca <- PCA(waterquality_pre[,!names(waterquality_pre) %in% c("is_safe")], graph = FALSE)
eig.val <- get_eigenvalue(res.pca)
eig.val
```

```{r}
res.pca <- PCA(waterquality_pre[,!names(waterquality_pre) %in% c("is_safe")], graph = FALSE, ncp = 10, scale = TRUE)
```

```{r}
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
var <- get_pca_var(res.pca)
fviz_pca_var(res.pca, col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Avoid text overlapping
             )
```

```{r}
ind <- get_pca_ind(res.pca)
```

```{r}
fviz_pca_ind(res.pca, col.ind = 'cos2', gradient.cols = c('#00AFBB', '#E7B800', '#FC4E07'),
repel = TRUE # Avoid text overlapping (slow if many points)
)
```

```{r}
split.data = function(data, p = 0.7, s = 1){
set.seed(s)
index = sample(1:dim(data)[1])
train = data[index[1:floor(dim(data)[1] * p)], ]
test = data[index[((ceiling(dim(data)[1] * p)) + 1):dim(data)[1]], ]
return(list(train=train, test=test)) } 
```

```{r}
dataframe_pca=as.data.frame(ind$coord)
dataframe_pca$is_safe = waterquality_pre$is_safe
```

PARTE DECISION TREE

```{r}
allset= split.data(dataframe_pca, s = 333)
trainset= allset$train
testset= allset$test
prop.table(table(trainset$is_safe))
```

```{r}
train_models = function(dataframe, grid, tipo, s = 44){

  set.seed(s)
  # Define the number of folds
  k = 10
  
  # Split the data into k folds
  folds = createFolds(dataframe$is_safe, k = k)
  str(folds)
  # Define an empty list to store the models
  models = list()
  
  # Loop through the grid of parameter values
  for (i in 1:nrow(grid)) {
      # Define an empty vector to store the accuracy
      accuracy = numeric()
      # Loop through the k-folds
      for (j in 1:k) {
          # Get the training and testing sets
          train_ind = folds[[j]]
          test_ind = -train_ind
          
          train_data = dataframe[train_ind, ]
          test_data = dataframe[test_ind, ]
        
          # Fit the model
          if(tipo == "rpart")
          {
            model = rpart(is_safe ~ ., 
                             data = train_data, 
                             method = "class",
                             control = rpart.control(
                               minsplit = grid[i, "minsplit"],
                               maxdepth = grid[i, "maxdepth"]))
          }
          else{
            model = svm(is_safe ~ ., 
                        data=train_data,
                        kernel = grid[i, "kernel"],
                        cost = grid[i, "C"],
                        epsilon = grid[i, "epsilon"])
          }
        
          # Make predictions on the test data
          predictions = predict(model, test_data, type = "class")
          
          confusion.matrix.model = table(test_data$is_safe, predictions)
          accuracy[j] = sum(diag(confusion.matrix.model))/sum(confusion.matrix.model)
      }
    
      # Store the model and its mean accuracy in the list
      models[[i]] = list(model = model, mean_accuracy = mean(accuracy))
  }
  
  # Find the model with the highest mean accuracy
  best_model = models[[which.max(sapply(models, function(x) x$mean_accuracy))]]
  
  # View the best model
  return(best_model$model)
}
```

```{r}
#######
# train_control = trainControl(method="repeatedcv", number=10, repeats=3)
```

```{r}
set.seed(33)
control = trainControl(method = "repeatedcv", number = 10,repeats = 3)
train.tree.model= train(is_safe ~ ., data = trainset, method = "rpart",  trControl = control)
model.tree = train.tree.model$finalModel
# model.tree = train(is_safe ~ ., data = trainset, method="rpart", trcontrol= train_control)
```

```{r}
train.tree.model
```

```{r}
fancyRpartPlot(model.tree)
```

```{r}
test.set = testset[,!names(testset) %in% c("is_safe")]
```

```{r}
# plotcp(model.tree$finalModel)
```

```{r}
# model.treePR = prune(model.tree$finalModel, cp=.05)
```

```{r}
# fancyRpartPlot(model.treePR)
```

```{r}
# testset$PredictionPR <- predict(model.treePR, test.tree, type = "class")
# result.treePR = confusionMatrix(testset$PredictionPR, testset[,c("is_safe")], mode = "prec_recall")
# result.treePR
```

```{r}
testset$Prediction <- predict(model.tree, test.set, type = "class")
result.tree = confusionMatrix(testset$Prediction, testset[,c("is_safe")], mode = "prec_recall")
result.tree
```

PARTE SVM

```{r}
# grid_svm = expand.grid(C = c(1), kernel = c("radial"), epsilon = c(0.1))
# svm.model = train_models(trainset, grid_svm, "svm", 42)
#svm.model = svm(is_safe ~ ., data=trainset, kernel='radial', cost=1, scale=TRUE) 
```

```{r}
# print(svm.model)
```

```{r}
# test.svm = testset[,!names(testset) %in% c("is_safe","Prediction","PredictionPR")]
```

```{r}
# svm.pred = predict(svm.model, test.svm)

```

```{r}
# result.svm = confusionMatrix(svm.pred, testset$is_safe, mode = "prec_recall")
# result.svm
```

```{r}
# grid_svmT = expand.grid(C = c(1, 10, 100), kernel = c("radial", "polynomial", "linear"), epsilon = c(0.01, 0.001))
# svmT.model = train_models(trainset, grid_svmT, "svm", 42)
```

```{r}
grid_svmT = expand.grid(C = c(0.1, 1, 10), sigma = c(0.1, 1, 10))
```

```{r}
set.seed(33)
#train.svm.model = train(is_safe ~ ., data = trainset, method = "svmRadial", tuneGrid = grid_svmT,  trControl = control)
train.svm.model = train(is_safe ~ ., data = trainset, method = "svmRadial",  trControl = control)
model.svm = train.svm.model$finalModel
```

```{r}
train.svm.model
```

```{r}
svm.pred = predict(train.svm.model, test.set)
```

```{r}
result.svm = confusionMatrix(svm.pred, testset$is_safe, mode = "prec_recall")
result.svm
```

PARTE ROC E AUC PER SINGOLO MODELLO

```{r}
generate_roc_single_model = function(model, test, targetoption, typemodel){
  pred.model.prob = predict(model, test[,!names(test) %in% c("is_safe")], type = "prob")
  # if(typemodel == "svm")
  #   pred.model.prob = predict(model,test[, !names(test) %in% c("is_safe")], probability=TRUE) 

  print(pred.model.prob)
  pred.model.prob.targoption = pred.model.prob[, targetoption]
  print(pred.model.prob.targoption)
  
  pred.rocr.model = prediction(pred.model.prob.targoption, test$is_safe)
  perf.rocr.model = performance(pred.rocr.model, measure = "auc", x.measure = "cutoff")
  
  if(targetoption == 2){
    tr = "tpr"
    fr = "fpr"
  }
  else{
    tr = "tnr"
    fr = "fnr"
  }
  perf.targoption.rocr.model = performance(pred.rocr.model, tr, fr)
  plot(perf.targoption.rocr.model, colorize = T, main=paste("AUC:",(perf.rocr.model@y.values)))
  abline(a=0, b=1)
  
  return(list("tr" = perf.targoption.rocr.model, "pred.rocr" =pred.rocr.model))
}
```

```{r}
tree.value.roc.t = generate_roc_single_model(train.tree.model, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 2, "rpart")

```

```{r}
tree.value.roc.n = generate_roc_single_model(train.tree.model, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 1, "rpart")
```

```{r}
set.seed(33)
control_p = trainControl(method = "repeatedcv", number = 10,repeats = 3, classProbs = TRUE)
train.svm.model.prob = train(make.names(is_safe) ~ ., data = trainset, method = "svmRadial",  trControl = control_p)
```

```{r}
svm.value.roc.t = generate_roc_single_model(train.svm.model.prob, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 2, "svm")
```

```{r}
svm.value.roc.n = generate_roc_single_model(train.svm.model.prob, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 1, "svm")
```

```{r}
# pred.treePR.prob = predict(model.treePR, test.tree, type = "prob")
# pred.treePR.prob.safe = pred.treePR.prob[, 2] 
# pred.treePR.prob.not_safe = pred.treePR.prob[, 1]
```

```{r}
# #pred.rocr.treePR = prediction(pred.treePR.roc, testset$is_safe) 
# pred.rocr.treePR = prediction(pred.treePR.prob.safe, testset$is_safe) 
# perf.rocr.treePR = performance(pred.rocr.treePR, measure = "auc", x.measure = "cutoff")
# perf.tpr.rocr.treePR = performance(pred.rocr.treePR, "tpr","fpr")
```

```{r}
# plot(perf.tpr.rocr.treePR, colorize=T,main=paste("AUC:",(perf.rocr.treePR@y.values))) 
# abline(a=0, b=1)
```

```{r}
# generate_roc_single_model(svmT.model, testset[,!names(testset) %in% c("Prediction","PredictionPR")], 2, "rpart")
```

```{r}
# pred.model.prob = predict(svmT.model, testset[,!names(testset) %in% c("is_safe","Prediction","PredictionPR")], probability = T)
```

```{r}
# tuned2 = tune.svm(is_safe ~ ., data = trainset,kernel='radial',
# cost=c(10,0.1,1,0.01), prob = TRUE)
# pred.svmT.prob = predict(tuned2$best.model, test.tree, probability=TRUE)
# prob.svmT = attr(pred.svmT.prob, "probabilities")
# pred.svmT.roc = prob.svmT[, 2] 
```

```{r}
# pred.rocr.svmT = prediction(pred.svmT.roc, testset$is_safe  ) 
# perf.rocr.svmT = performance(pred.rocr.svmT, measure = 'auc', x.measure = 'cutoff')
# perf.tpr.rocr.svmT = performance(pred.rocr.svmT, "tpr","fpr") 

```

```{r}
# plot(perf.tpr.rocr.svmT, colorize=T,main=paste("AUC:",(perf.rocr.svmT@y.values)))
# abline(a=0, b=1)
```

PARTE OPT CUT

```{r}
opt.cut = function(perf, pred){
 cut.ind = mapply(FUN=function(x, y, p){
 d = (x - 0)^2 + (y-1)^2
 ind = which(d == min(d))
 c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
 cutoff = p[[ind]])
 }, perf@x.values, perf@y.values, pred@cutoffs)
}
```

```{r}
print_all_cutoff = function(perf.tpr.rocr, pred.rocr){
  print(opt.cut(perf.tpr.rocr, pred.rocr))
  #acc.perf = performance(tree.value.roc.t$pred.rocr, measure = "acc")
  #plot(acc.perf)
  #inde = which.max( slot(acc.perf, "y.values")[[1]] )
  #acc = slot(acc.perf, "y.values")[[1]][inde]
  #cutoff = slot(acc.perf, "x.values")[[1]][inde]
  #print(c(accuracy= acc, cutoff = cutoff))
}
```

```{r}
print_all_cutoff(tree.value.roc.t$tr, tree.value.roc.t$pred.rocr)
```

```{r}
print_all_cutoff(tree.value.roc.n$tr, tree.value.roc.n$pred.rocr)
```

```{r}
print_all_cutoff(svm.value.roc.t$tr, tree.value.roc.n$pred.rocr)
```

```{r}
print_all_cutoff(svm.value.roc.n$tr, tree.value.roc.n$pred.rocr)
```

```{r}
print(opt.cut(tree.value.roc.t$tr, tree.value.roc.t$pred.rocr))
```

```{r}
acc.perf = performance(tree.value.roc.t$pred.rocr, measure = "acc")
plot(acc.perf)
```

```{r}
inde = which.max( slot(acc.perf, "y.values")[[1]] )
acc = slot(acc.perf, "y.values")[[1]][inde]
cutoff = slot(acc.perf, "x.values")[[1]][inde]
print(c(accuracy= acc, cutoff = cutoff))

```

PARTE COMPARAZIONE MODELLI

```{r}
comp_models_roc = function(model, testset, s, targetout){
  probs = predict(model, testset[,! names(testset) %in% c("is_safe")], type = "prob")
  colnames(probs)[1] ="not_safe"
  colnames(probs)[2] ="safe"
  if(targetout == 1){
    ROC = roc(response = testset[,c("is_safe")], predictor = probs$not_safe,
  levels = levels(testset[,c("is_safe")]))
  }
  else{
      ROC = roc(response = testset[,c("is_safe")], predictor = probs$safe,
  levels = levels(testset[,c("is_safe")]))
    }
  return(ROC)
}
```

```{r}
set.seed(33)
control_f = trainControl(method = "repeatedcv", number = 10,repeats = 3,
classProbs = TRUE, summaryFunction = twoClassSummary)
model.tree.roc= train(make.names(is_safe) ~ ., data = trainset, method = "rpart", metric = "ROC", trControl = control_f)
model.svm.roc = train(make.names(is_safe) ~ ., data = trainset, method = "svmRadial", metric = "ROC", trControl = control_f)
```

```{r}
comp_tree = comp_models_roc(model.tree.roc, testset[,! names(testset) %in% c("Prediction", "PredictionT")], 33, 2)
plot(comp_tree,type="S", col="blue")

comp_svm = comp_models_roc(model.svm.roc, testset[,! names(testset) %in% c("Prediction", "PredictionT")], 33, 2)
plot(comp_svm,add = TRUE, col="green")
```

```{r}
comp_svm
comp_tree
```

```{r}
cv.values = resamples(list(svm=model.svm.roc, rpart = model.tree.roc))
summary(cv.values)
```

```{r}
dotplot(cv.values, metric = "ROC") 

```

```{r}
bwplot(cv.values, layout = c(3, 1)) 

```

```{r}
splom(cv.values,metric="ROC")
```
